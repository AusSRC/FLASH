# flashdb is hosted on 146.118.64.208
#
# Check that the port is remotely accessible by running (on the remote machine) one of these:
nc -vz 146.118.64.208 5432
telnet 146.118.64.208 5432
#
# Tried to reset 'postgres' passwd to 'teapottery' but failed?
# Survey sbids start after SB 43426
#
######### Psycopg2 ###########################################

# install psycopg2 
sudo apt install pip
sudo apt-get install --reinstall libpq-dev
sudo pip install psycopg2
#######################################################################################################

ssh -i ~/src/aussrc.pem ubuntu@146.118.64.208

sudo -u postgres psql
create user flash with password 'aussrc'; 
# can change the passwd with: alter user flash with password 'testing';

drop database flashdb with (FORCE);
create database flashdb;
grant all privileges on database flashdb to flash;

# Re-login as flash user:
psql -U flash -d flashdb

#######################################################################################################
########## Create the tables:
#######################################################################################################
#
# The spect_run and detect_run tables give HPC-related resource info on the environment for the 
# processing run. Originally the idea was to have these as parents of multiple SBID processing jobs,
# but in practice we have a unique spect_run (and detect_run when it is processed) for each SBID.
#


create table spect_run (
    id int generated always as identity PRIMARY KEY,
    SBIDs int[],
    config_tar bytea,
    errlog text,
    stdlog text,
    platform varchar(50),
    run_tag varchar(100),
    date TIMESTAMP
);

create table detect_run (
    id int generated always as identity PRIMARY KEY,
    SBIDs int[],
    config_tar bytea,
    errlog text,
    stdlog text,
    result_filepath varchar(100),
    results text,
    platform varchar(50),
    run_tag varchar(100), 
    date TIMESTAMP
);
#######################################################################################################
#######################################################################################################
# SBID - primary table for observation bundle data. Columns are:
#       id - generated primary key
#       sbid_num - SBID number (per CASDA)
#
# These three are technically one to many (parent to child), but in practice are only one to one
#       spect_runid - id of parent spectral run
#       detect_runid - id of parent detection run
#       invert_detect_runid - id of parent inverted_spectra detection run
# 
#       spectralF - has spectral processing been done? Should always be True
#       detectionF - has detection processing been done?
#       invert_detectionF - has inverted-spectra detection processing been done?
#
#       spectral_config_tar - tarball of the spectral processing config files as a byte array
#       detect_config_tar - tarball of the detection processing config files as a byte array
#       pointing - the FLASH pointing field (as per CASDA)
#       quality - one of 'GOOD','BAD','UNCERTAIN','REJECTED','NOT_VALIDATED', as per CASDA
#
#       ascii_tar - tarball of spectral processsing output ascii files (as an lob)
#
# These two will be depricated in favour of the byte array versions:
#       detect_tar - tarball of detection processsing output stats,results and small plot files (as an lob)
#       invert_detect_tar - tarball of inverted-spectra detection processsing output stats,results and small plot files (as an lob)
#
#       detect_results - byte array version of detect_tar
#       invert_detect_results - byte array version of invert_detect_tar
#
#       results - the results.dat table from the detection
#       invert_results - the results.dat table from the inverted_spectra detection
#
#       version - can have many versions of the same sbid_num (will have a different id)
#       comment - a text comment field

create table SBID (
    id int generated always as identity PRIMARY KEY,
    sbid_num int NOT NULL,
    spect_runid int,
    detect_runid int,
    invert_detect_runid int,
    spectralF boolean,
    detectionF boolean,
    invert_detectionF boolean,
    spectral_config_tar bytea,
    detect_config_tar bytea,
    pointing text,
    quality varchar(50),
    ascii_tar oid,
    detect_tar oid,
    invert_detect_tar oid,
    detect_results bytea,
    invert_detect_results bytea,
    results text,
    invert_results text,
    version int NOT NULL,
    comment text
);

alter table SBID drop constraint check_types;
alter table SBID add constraint check_types check (quality in ('GOOD','BAD','UNCERTAIN','REJECTED','NOT_VALIDATED') );

#######################################################################################################
#######################################################################################################
# component - primary table for a source within an SBID
#       id - generated primary key
#       comp_id - full name as per CASDA catalogue
#       shortname - just the component number eg '100f'
#       component_name - catalogue id eg 'J024552-095841'
#       ra_hms_cont - right ascention in hours min sec
#       dec_dms - declination in degrees min sec
#       ra_deg_cont - right ascention in decimal degrees
#       dec_deg_cont - declination in decimal degrees
#       processState - one of 'spectral', 'detection' or 'inverted_detection'
#       opd_plotname - name of the associated optical density plot file
#       flux_plotname - name of the associated flux plot file
#       fluxfilter - min flux in mJy that was processed (this should be in SBID, as it's the same for all sources)
#       flux_cutoff - NOT USED
#       flux_peak - max flux value for this source
#       flux_int max intergrated flux for this source
#       has_siblings - NOT USED
#       opd_image - the actual optical density pdf file as a byte array
#       flux_image - the actual flux pdf file as a byte array
#       mode_num - generated by the detection process - roughly how many candidate absorptions found
#       invert_mode_num - generated by the inverted spectra detection - roughly how many candidate absorptions found
#       ln_mean - generated by the detection process - roughly how statistically positive the detection is
#       invert_ln_mean - generated by the inverted-spectra detection - roughly how statistically positive the detection is
#       spectral_date - timestamp of when the spectral processing was done
#       detection_date - timestamp of when the detection processing was done
#       invert_detection_date - timestamp of when the inverted-spectra detection processing was done
#       sbid_id - the id of the parent SBID entry (one SBID to many sources)
#       comment - a text comment

create table component (
    id int generated always as identity PRIMARY KEY,
    comp_id varchar(100) NOT NULL,
    shortname char(5),
    component_name varchar(100),
    ra_hms_cont varchar(50,
    dec_dms_cont varchar(50,
    ra_deg_cont varchar(50,
    dec_deg_cont varchar(50,
    processState varchar(50) NOT NULL,
    opd_plotname varchar(100),
    flux_plotname varchar(100),
    fluxfilter real,
    flux_cutoff varchar(50),
    flux_peak real,
    flux_int real,
    has_siblings int,
    opd_image bytea,
    flux_image bytea,
    mode_num int,
    invert_mode_num int,
    ln_mean real,
    invert_ln_mean real,
    spectral_date TIMESTAMP,
    detection_date TIMESTAMP,
    invert_detection_date TIMESTAMP,
    sbid_id int NOT NULL,
    comment text,
    constraint fk_sbid_id
        foreign key(sbid_id) references SBID(id) on delete cascade
);

alter table component drop constraint fk_sbid_id; # No longer need this - it slows down deletes

# This should be done for all BYTEA columns that store compressed data (to stop Postgresql from trying to re-compress):
#alter table component alter column opd_image set storage EXTERNAL;

# Don't use this anymore:
alter table component add constraint check_flux check (flux_cutoff in ('ABOVE','BELOW') );

#######################################################################################################
#######################################################################################################
# Black listed: This table lists sbids and optionally components of sbids, that are not to be processed 
# or stored in the database

create table black_list (
    id int generated always as identity PRIMARY KEY,
    sbid int NOT NULL,
    components int[]
);

#######################################################################################################
#######################################################################################################
create table reports (
    id int generated always as identity PRIMARY KEY,
    name varchar(100) NOT NULL,
    author varchar(100) NOT NULL,
    sbid_id int,
    spect_runid int,
    detect_runid int,
    report oid,
    date TIMESTAMP
);

#########################################################################################
######### NOT USED ######################################################################

alter TABLE spect_run ADD COLUMN run_tag varchar(100);
update spect_run set run_tag = 'flash survey 1';
alter TABLE detect_run ADD COLUMN run_tag varchar(100);
update detect_run set run_tag = 'flash survey 1';
# Search in ARRAY
update spect_run set run_tag = 'ASKAP pilot' where 15211 = any(sbids);

# Insert into table with array and date values
insert into spect_run(sbids,date,run_tag) values(array[11051,11052],current_timestamp,'flash pilot 1');

# Join table:
select sbid.id,sbid.spect_runid,spect_run.run_tag from sbid inner join spect_run on sbid.spect_runid = spect_run.id where spect_run.run_tag like '%pilot%';
# Join 3 tables:
select c.comp_id,c.component_name,c.flux_peak,c.has_siblings,p.run_tag from component c inner join SBID s  on s.id = c.sbid_id inner join spect_run p on p.id = s.spect_runid where p.run_tag like '%survey 1' order by c.comp_id;
select distinct s.sbid_num from component c inner join SBID s on s.id = c.sbid_id where c.flux_peak < 45;

# Update with join:
update sbid s set version = 1 from spect_run r where s.spect_runid = r.id and r.run_tag = 'FLASH Survey 1';
update sbid s set spectral_config_tar = r.config_tar from spect_run r where s.spect_runid = r.id;
update sbid s set results = r.results from detect_run r where s.spect_runid = r.id;

# Finding large objects:
select oid, s.sbid_num from pg_largeobject_metadata m inner join sbid s on m.oid = s.detect_tar;
# delete large object:
lo_unlink(oid)

# Delete duplicate records - join table to itself:
delete from component a using component b where a.id < b.id and a.comp_id = b.comp_id;

# Changing primary keys:
alter table sbid drop constraint sbid_pkey cascade;
alter table sbid add column id serial primary key;

# Changing primary key on large table:
alter table component drop constraint component_pkey;
alter table component add column id int;
UPDATE component SET id = t.rownum FROM (SELECT comp_id, row_number() OVER (ORDER BY spectral_date ASC) as rownum FROM component) t WHERE component.comp_id = t.comp_id;
alter table component alter column id set not null;
alter table component add constraint id_unique unique (id);
alter table component alter column id ADD GENERATED BY DEFAULT AS IDENTITY (start with 59034);


# Adding dependent foreign key
alter table component add column sbid_id int;
update component c set sbid_id = id from sbid s where c.sbid = s.sbid_num;
alter table component add constraint fk_sbid_id foreign key(sbid_id) REFERENCES sbid(id) on delete cascade;

# Getting list of BAD components:
select c.comp_id,c.component_name,s.sbid_num, s.pointing, c.comment as FIELD from component c inner join sbid s on s.id = c.sbid_id where c.processState = 'BAD' order by s.sbid_num;

# Getting list of BAD components, splitting the comp_id, eg 'spec_SB45762_component_84a.fits' becomes 'SB45762_component_84a':
select s.sbid_num,split_part(split_part(c.comp_id,'spec_',2),'.fits',1),c.component_name, s.pointing, c.comment as FIELD from component c inner join sbid s on s.id = c.sbid_id where c.processState = 'BAD' order by s.sbid_num;

#########################################################################################
######## Delete tables ######################################
drop table detection cascade;
drop table spectral_plot cascade;
drop table component cascade;
drop table sbid cascade;
drop table detect_run cascade;
drop table spect_run cascade;


# To read in binary/text data, user flash needs the following grants.
# Add as superuser (attached to 'flashdb' database) :
GRANT EXECUTE ON FUNCTION pg_read_binary_file(text) TO flash;
GRANT EXECUTE ON FUNCTION pg_read_binary_file(text,bigint,bigint) TO flash;
GRANT EXECUTE ON FUNCTION pg_read_binary_file(text,bigint,bigint,boolean) TO flash;
GRANT EXECUTE ON FUNCTION pg_read_file(text) TO flash;
GRANT EXECUTE ON FUNCTION pg_read_file(text,bigint,bigint) TO flash;
GRANT EXECUTE ON FUNCTION pg_read_file(text,bigint,bigint,boolean) TO flash;
    
#########################################################################################
######## Creating Functions ######################################
# Function to find size of lob
CREATE OR REPLACE FUNCTION get_lo_size(oid) RETURNS bigint
VOLATILE STRICT
LANGUAGE 'plpgsql'
AS $$
DECLARE
    fd integer;
    sz bigint;
BEGIN
    -- Open the LO; N.B. it needs to be in a transaction otherwise it will close immediately.
    -- Luckily a function invocation makes its own transaction if necessary.
    -- The mode x'40000'::int corresponds to the PostgreSQL LO mode INV_READ = 0x40000.
    fd := lo_open($1, x'40000'::int);
    -- Seek to the end.  2 = SEEK_END.
    PERFORM lo_lseek(fd, 0, 2);
    -- Fetch the current file position; since we're at the end, this is the size.
    sz := lo_tell(fd);
    -- Remember to close it, since the function may be called as part of a larger transaction.
    PERFORM lo_close(fd);
    -- Return the size.
    RETURN sz;
END;
$$; 

# Use function as:
SELECT get_lo_size(1234567);
SELECT pg_size_pretty(get_lo_size(1234567));

# Function to delete components one by one - note this will fail if there are no components (sources) stored
# for the sbid:
CREATE OR REPLACE FUNCTION delete_comps(integer) RETURNS void 
LANGUAGE 'plpgsql'
AS $$
DECLARE
    comp_arr integer[];
BEGIN
    select array_agg(id::integer) into comp_arr from component where sbid_id = $1;
    raise NOTICE 'array: %',comp_arr;
    FOR i in 1..CARDINALITY(comp_arr) LOOP
        delete from component where id = comp_arr[i];
        raise NOTICE 'deleted % component %', i, comp_arr[i];
    END LOOP;
END;
$$;

# Use function as:
SELECT delete_comps(310);

############################################################################################
ï¿¼
# Find the objects / tables taking up the most space in the database:
SELECT oid::regclass, pg_relation_size(oid), relkind FROM pg_class ORDER BY 2 DESC;

# Find storage and data types used in database:
SELECT table_name, column_name, attstorage, atttypid::regtype FROM information_schema.columns JOIN pg_attribute ON ( columns.table_name = pg_attribute.attrelid::regclass::text AND columns.column_name = pg_attribute.attname) where table_name = 'sbid';

#################################################
# Find sbids with duplicate components:
select distinct s.id,s.sbid_num from sbid s inner join component c on s.id = c.sbid_id where c.comp_id in (select comp_id from component group by comp_id having count(*) > 1) order by s.sbid_num;


# Delete duplicates:
DELETE from component where id in (select id from component except (select max(id) from component group by comp_id));
DELETE from component where id in (select id from component except (select max(id) from component where sbid_id = 372 group by comp_id));

#################################################
# run long-running transactions from the command line and disconnect:
psql -U flash -d flashdb -c 'update component set opd_image = NULL where sbid_id = 312' &
bg
disown

######################################################################################################
####### Dumping and Restoring ########################################################################

# First step is removing orphaned large objects:
# You can use the utility 'vacuumlo' outside of postgres, ie on the linux command line:
vacuumlo -U flash -v flashdb >> pg_vacuum.txt 2>&1
# as the above will take a long time, background and disown it. Then run:
vacuumdb -U flash -v -d flashdb

# As the tables SBID and Component make a lot of use of bytea (byte array) data, you should NOT
# use compression when calling pg_dump, ie use the flag '-Z0', then compress outside of pg_dump

# You can call pg_dump with multi-threading eg '-j 10' 

# Example:
pg_dump -Z0 -j 10 -Fd flashdb -f /mnt/tmp
tar -czf flashdb.tar.gz /mnt/tmp

#################################################
